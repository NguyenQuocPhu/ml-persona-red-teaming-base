########## CONFIGURATION ##########

# Archive Configuration
archive: 
  path: [./configs/categories/categories.txt, ./configs/styles/styles.txt]
  descriptor: [Risk Category, Attack Style]
memory:
  path_top_prompts:
  path_bot_prompts:
# Seed dataset
sample_prompts: ./data/do-not-answer.json

# Target LLM Configuration (RẤT NHỎ)
target_llm:
  type_: vllm
  model_kwargs:
    # Model 0.5 Tỷ tham số, rất nhỏ
    model: Qwen/Qwen1.5-0.5B-Chat 
    trust_remote_code: True
    max_model_len: 2048
    gpu_memory_utilization: 0.9
    dtype: half
    swap_space: 8
    device: "0" # <--- Chạy trên GPU 0
    enforce_eager: True
  sampling_params:
    temperature: 0.6
    top_p: 0.9
    max_tokens: 1024

# Mutator LLM Configuration (NHỎ)
mutator_llm: 
  type_: vllm
  model_kwargs:
    # Model 1.1 Tỷ tham số
    model: TinyLlama/TinyLlama-1.1B-Chat-v1.0 
    trust_remote_code: True
    gpu_memory_utilization: 0.9
    max_model_len: 2048
    dtype: half
    swap_space: 8
    device: "1" # <--- Chạy trên GPU 1
    enforce_eager: True
  sampling_params:
    temperature: 0.7
    top_p: 0.9
    max_tokens: 128

# Fitness LLM Configuration (RẤT NHỎ)
fitness_llm: 
  type_: vllm
  model_kwargs:
    # Model 0.5 Tỷ tham số, rất nhỏ
    model: Qwen/Qwen1.5-0.5B-Chat 
    trust_remote_code: True
    gpu_memory_utilization: 0.9
    max_model_len: 4096
    dtype: half
    swap_space: 8
    device: "0" # <--- Chạy trên GPU 0
    enforce_eager: True
  sampling_params:
    temperature: 0.7
    top_p: 0.9
    max_tokens: 16
    logprobs: 1