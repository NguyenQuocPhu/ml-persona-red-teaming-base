import time
import logging
import google.generativeai as genai
from typing import Any, Dict, List # Cáº§n thÃªm List cho batch_generate

# Import Exception chuáº©n cá»§a Google
from google.api_core.exceptions import ResourceExhausted, InternalServerError

# Giá»¯ nguyÃªn pháº§n import BaseLLM cá»§a dá»± Ã¡n báº¡n

from rainbowplus.llms.base import BaseLLM

logger = logging.getLogger(__name__)

class GeminiLLM(BaseLLM):
    def __init__(self, config: Any):
        super().__init__()
        self.config = config

        model_kwargs = getattr(config, "model_kwargs", {}) or {}
        
        # 1. Cáº¥u hÃ¬nh API Key & Model
        self.api_key = model_kwargs.get("api_key")
        self.model_name = model_kwargs.get("model", "gemini-1.5-flash")
        
        # 2. Cáº¥u hÃ¬nh Rate Limit (RPM)
        self.rpm = model_kwargs.get("rpm", 10) 
        self.min_interval = 60.0 / float(self.rpm)
        self.last_call_time = 0.0

        if self.api_key:
            genai.configure(api_key=self.api_key)
        else:
            logger.error("âŒ ERROR: Thiáº¿u 'api_key' trong config!")

        self._model = None

    def _ensure_model_client(self):
        if self._model is None and self.api_key:
            self._model = genai.GenerativeModel(self.model_name)

    # --- Sá»¬A Lá»–I: ThÃªm hÃ m get_name theo yÃªu cáº§u cá»§a BaseLLM ---
    def get_name(self) -> str:
        return self.model_name

    def _wait_for_rate_limit(self):
        """Chá»§ Ä‘á»™ng ngá»§ Ä‘á»ƒ Ä‘áº£m báº£o khÃ´ng vÆ°á»£t quÃ¡ RPM"""
        now = time.time()
        elapsed = now - self.last_call_time
        if elapsed < self.min_interval:
            sleep_time = self.min_interval - elapsed
            time.sleep(sleep_time)

    def generate(self, prompt: str, sampling_params: Dict[str, Any] = None, max_retries: int = 5) -> str:
        if not self.api_key: return ""
        self._ensure_model_client()

        default_params = dict(getattr(self.config, "sampling_params", {}) or {})
        if sampling_params: default_params.update(sampling_params)
        
        gen_config = genai.GenerationConfig(
            temperature=default_params.get("temperature", 0.7),
            max_output_tokens=default_params.get("max_tokens", 1024),
            top_p=default_params.get("top_p", 0.9)
        )

        for attempt in range(max_retries):
            try:
                self._wait_for_rate_limit() # 1. Chá» RPM

                response = self._model.generate_content(prompt, generation_config=gen_config)
                
                self.last_call_time = time.time() # 2. Cáº­p nháº­t thá»i gian

                if response.text:
                    return response.text
                return ""

            except ResourceExhausted:
                # Lá»—i 429: QuÃ¡ táº£i -> Ngá»§ lÃ¢u hÆ¡n
                wait_time = (2 ** attempt) + 2
                logger.warning(f"âš ï¸ Rate Limit (429). Waiting {wait_time}s...")
                time.sleep(wait_time)
                self.last_call_time = time.time()

            except InternalServerError:
                time.sleep(2)
            
            except Exception as e:
                logger.error(f"Generate Error: {e}")
                break
        
        return ""

    # --- Sá»¬A Lá»–I: ThÃªm hÃ m batch_generate ---
    def batch_generate(self, prompts: List[str], sampling_params: Dict[str, Any] = None) -> List[str]:
        """
        Xá»­ lÃ½ danh sÃ¡ch prompt tuáº§n tá»± Ä‘á»ƒ Ä‘áº£m báº£o an toÃ n Rate Limit.
        """
        results = []
        total = len(prompts)
        logger.info(f"ğŸš€ Báº¯t Ä‘áº§u batch generate cho {total} prompts vá»›i model {self.model_name}...")
        
        for i, prompt in enumerate(prompts):
            # Gá»i láº¡i hÃ m generate (Ä‘Ã£ cÃ³ sáºµn logic chá»/ngá»§ bÃªn trong)
            res = self.generate(prompt, sampling_params)
            results.append(res)
            
            # Log tiáº¿n Ä‘á»™ má»—i 10 cÃ¢u Ä‘á»ƒ Ä‘á»¡ spam log
            if (i + 1) % 10 == 0:
                logger.info(f"   ...ÄÃ£ xá»­ lÃ½ {i + 1}/{total} prompts.")
                
        return results